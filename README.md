ğŸš€ ğ—¨ğ—»ğ—¹ğ—¼ğ—°ğ—¸ğ—¶ğ—»ğ—´ ğ—£ğ—®ğ—¿ğ—®ğ—¹ğ—¹ğ—²ğ—¹ ğ—£ğ—¼ğ˜ğ—²ğ—»ğ˜ğ—¶ğ—®ğ—¹: ğ—›ğ—¶ğ—´ğ—µ-ğ—£ğ—²ğ—¿ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ—»ğ—°ğ—² ğ—–++ğŸ­ğŸ³ ğ— ğ—®ğ˜‡ğ—² ğ—¦ğ—¼ğ—¹ğ˜ƒğ—²ğ—¿ ğ—”ğ—»ğ—®ğ—¹ğ˜†ğ˜€ğ—¶ğ˜€

I built high-performance, multi-threaded maze solvers in C++17, optimized for high-end multicore CPUs.

1ï¸âƒ£ ğ—§ğ—²ğ—°ğ—µ ğ—¦ğ˜ğ—®ğ—°ğ—¸

To fully exploit the hardware capabilities of the i9-14900KF, all algorithms were implemented using the ğ—–++ğŸ­ğŸ³ ğ— ğ˜‚ğ—¹ğ˜ğ—¶-ğ˜ğ—µğ—¿ğ—²ğ—®ğ—± ğ—Ÿğ—¶ğ—¯ğ—¿ğ—®ğ—¿ğ˜†. This choice was critical for reducing overhead in synchronization primitives (mutexes, atomics) and maximizing thread throughput in the concurrent solvers.

2ï¸âƒ£ ğ—”ğ—¹ğ—´ğ—¼ğ—¿ğ—¶ğ˜ğ—µğ—ºğ˜€

ğ˜šğ˜ªğ˜¯ğ˜¨ğ˜­ğ˜¦ ğ˜›ğ˜©ğ˜³ğ˜¦ğ˜¢ğ˜¥ ğ˜‰ğ˜ğ˜š (ğ˜‰ğ˜³ğ˜¦ğ˜¢ğ˜¥ğ˜µğ˜©-ğ˜ğ˜ªğ˜³ğ˜´ğ˜µ ğ˜šğ˜¦ğ˜¢ğ˜³ğ˜¤ğ˜©) ğŸ“:

  â€¢ ğ— ğ—²ğ—°ğ—µğ—®ğ—»ğ—¶ğ˜€ğ—º: Explores the maze layer-by-layer using a queue. Guarantees the shortest path (in unweighted graphs) but requires massive memory and processing for deep mazes.
  
  â€¢ ğ—£ğ—¿ğ—¼ğ˜€/ğ—–ğ—¼ğ—»ğ˜€: Simple to implement, but suffers from exponential search space expansion in large mazes.

ğ˜šğ˜ªğ˜¯ğ˜¨ğ˜­ğ˜¦ ğ˜›ğ˜©ğ˜³ğ˜¦ğ˜¢ğ˜¥ ğ˜‹ğ˜ğ˜š (ğ˜‹ğ˜¦ğ˜±ğ˜µğ˜©-ğ˜ğ˜ªğ˜³ğ˜´ğ˜µ ğ˜šğ˜¦ğ˜¢ğ˜³ğ˜¤ğ˜©) ğŸ—‚:

  â€¢ ğ— ğ—²ğ—°ğ—µğ—®ğ—»ğ—¶ğ˜€ğ—º: Explores the maze layer-by-layer using a queue. Guarantees the shortest path (in unweighted graphs) but requires massive memory and processing for deep mazes.
  
  â€¢ ğ—£ğ—¿ğ—¼ğ˜€/ğ—–ğ—¼ğ—»ğ˜€: Memory efficient and often faster than BFS on single-solution mazes, but can get "lucky" ğŸ€ or "unlucky" ğŸ’€ depending on branch ordering.

ğ˜”ğ˜¶ğ˜­ğ˜µğ˜ªğ˜±ğ˜­ğ˜¦ ğ˜›ğ˜©ğ˜³ğ˜¦ğ˜¢ğ˜¥ğ˜´ ğ˜”ğ˜¦ğ˜µğ˜©ğ˜°ğ˜¥ 1 (ğ˜—ğ˜¢ğ˜³ğ˜¢ğ˜­ğ˜­ğ˜¦ğ˜­ ğ˜—ğ˜³ğ˜¶ğ˜¯ğ˜ªğ˜¯ğ˜¨ + ğ˜‰ğ˜ªğ˜¥ğ˜ªğ˜³ğ˜¦ğ˜¤ğ˜µğ˜ªğ˜°ğ˜¯ğ˜¢ğ˜­) âœ‚ï¸:

  â€¢ ğ— ğ—²ğ—°ğ—µğ—®ğ—»ğ—¶ğ˜€ğ—º: Uses a concurrent "Prune and Pursue" strategy. Dedicated threads seal dead-ends, while a Bottom-to-Top (BT) thread executes a pruning-compatible BFS. Simultaneously, the Top-to-Bottom (TB) thread simply advances along the path carved by the pruning threads.
  
  â€¢ ğ—¢ğ—½ğ˜ğ—¶ğ—ºğ—¶ğ˜‡ğ—®ğ˜ğ—¶ğ—¼ğ—»: Efficiency is maximized by partitioning the maze into distinct sections, enabling interference-free parallel pruning. This dynamic reduction actively shrinks the search space in real-time, preventing the BT thread from wasting cycles on dead-ends and paving a clear path for the TB thread.

ğ˜”ğ˜¶ğ˜­ğ˜µğ˜ªğ˜±ğ˜­ğ˜¦ ğ˜›ğ˜©ğ˜³ğ˜¦ğ˜¢ğ˜¥ğ˜´ ğ˜”ğ˜¦ğ˜µğ˜©ğ˜°ğ˜¥ 2 (ğ˜Šğ˜°ğ˜­ğ˜­ğ˜¢ğ˜£ğ˜°ğ˜³ğ˜¢ğ˜µğ˜ªğ˜·ğ˜¦ ğ˜‰ğ˜ªğ˜¥ğ˜ªğ˜³ğ˜¦ğ˜¤ğ˜µğ˜ªğ˜°ğ˜¯ğ˜¢ğ˜­ ğ˜‹ğ˜ğ˜š) ğŸ”„:

  â€¢ ğ— ğ—²ğ—°ğ—µğ—®ğ—»ğ—¶ğ˜€ğ—º: Launches multiple threads split into two groups: one searching Top-to-Bottom (TB) and one Bottom-to-Top (BT).
  
  â€¢ ğ—¢ğ—½ğ˜ğ—¶ğ—ºğ—¶ğ˜‡ğ—®ğ˜ğ—¶ğ—¼ğ—»: Threads share a global "visited" state. When a thread enters a branch, it marks it "Occupied" ğŸš§ to prevent redundant work. Dead-ends are marked "Dead" ğŸ’€ globally, permanently pruning the search for all other threads. The search concludes when a TB thread overlaps with a BT thread.

3ï¸âƒ£ ğ—£ğ—²ğ—¿ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ—»ğ—°ğ—²

<img width="642" height="805" alt="image" src="https://github.com/user-attachments/assets/c1c2a4eb-0b5f-4760-a296-002884abb140" />

4ï¸âƒ£  ğ—”ğ—»ğ—®ğ—¹ğ˜†ğ˜€ğ—¶ğ˜€

  â€¢ ğ— ğ—§ ğ— ğ—²ğ˜ğ—µğ—¼ğ—± ğŸ­ (ğ—–ğ—¼ğ—»ğ—°ğ˜‚ğ—¿ğ—¿ğ—²ğ—»ğ˜ ğ—£ğ—¿ğ˜‚ğ—»ğ—¶ğ—»ğ—´) dominates on Server Hardware. It effectively exploits massive thread counts (180+) on low-frequency CPUs (AMD EPYC) to mass-delete dead ends, scaling linearly to achieve 0.26s (approx. 2.5x faster than Intel).
  
  â€¢ ğ— ğ—§ ğ— ğ—²ğ˜ğ—µğ—¼ğ—± ğŸ® (ğ—–ğ—¼ğ—¹ğ—¹ğ—®ğ—¯ğ—¼ğ—¿ğ—®ğ˜ğ—¶ğ˜ƒğ—² ğ—”ğ˜€ğ˜†ğ—ºğ—ºğ—²ğ˜ğ—¿ğ—¶ğ—° ğ—§ğ—¿ğ—®ğ˜ƒğ—²ğ—¿ğ˜€ğ—®ğ—¹ ğ——ğ—™ğ—¦) excels on High-Frequency Workstations by leveraging the Intel i9's clock speed. However, it also demonstrates strong scalability on high-core systems, improving to 0.30s on AMD (vs 0.36s on Intel), proving that its dynamic, differentiated thread roles benefit significantly from increased core density.
  
ğ—©ğ—²ğ—¿ğ—±ğ—¶ğ—°ğ˜:
Method 1 is the top choice for massive parallel throughput (Servers).
Method 2 offers a versatile balance, making it ideal for Workstations while remaining highly competitive and scalable on Server platforms.



ğŸ”— See the visualization of all algorithms in action:
 https://tangzhilinnz.github.io/maze_visualization/

---------------------

![Maze](https://github.com/user-attachments/assets/fa8af537-828c-4b64-878a-ed131d6cb63f)


